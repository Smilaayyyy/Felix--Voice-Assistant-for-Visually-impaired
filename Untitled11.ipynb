{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjRCY_R6uHer",
        "outputId": "4e6420d2-1333-43ae-b87f-b0cdba658c08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install -q git+https://github.com/openai/whisper.git\n",
        "%pip install -q gradio\n",
        "%pip install -q openai\n",
        "%pip install -q gTTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEXsxJ-cvJR-"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "import gradio as gr \n",
        "import time\n",
        "import warnings\n",
        "import json\n",
        "import openai\n",
        "import os\n",
        "from gtts import gTTS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IORC-hZ1vgrB"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "YH-DkM-6voqp"
      },
      "outputs": [],
      "source": [
        "openai.api_key = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "SPoddqCMwFWz"
      },
      "outputs": [],
      "source": [
        "model = whisper.load_model(\"base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnIeYX3TwPd-",
        "outputId": "62af89f4-96a2-450e-cb22-e1d93315226b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNpyJnnZwcK8",
        "outputId": "4c968114-19d0-47d7-b388-bc15952b4d2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "Input #0, lavfi, from 'anullsrc=r=44100:cl=mono':\n",
            "  Duration: N/A, start: 0.000000, bitrate: 352 kb/s\n",
            "    Stream #0:0: Audio: pcm_u8, 44100 Hz, mono, u8, 352 kb/s\n",
            "File 'Temp.mp3' already exists. Overwrite ? [y/N] ^C\n"
          ]
        }
      ],
      "source": [
        "!ffmpeg -f lavfi -i anullsrc=r=44100:cl=mono -t 10 -q:a 9 -acodec libmp3lame Temp.mp3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "HkggWdrSwpEV"
      },
      "outputs": [],
      "source": [
        "def chatgpt_api(input_text):\n",
        "    messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
        "    \n",
        "    if input_text:\n",
        "        messages.append(\n",
        "            {\"role\": \"user\", \"content\": input_text},\n",
        "        )\n",
        "        chat_completion = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\", messages=messages\n",
        "        )\n",
        "    \n",
        "    reply = chat_completion.choices[0].message.content\n",
        "    return reply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vtFsl1JYwuLf"
      },
      "outputs": [],
      "source": [
        "def transcribe(audio):\n",
        "\n",
        "    language = 'en'\n",
        "\n",
        "    audio = whisper.load_audio(audio)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "    _, probs = model.detect_language(mel)\n",
        "\n",
        "    options = whisper.DecodingOptions()\n",
        "    result = whisper.decode(model, mel, options)\n",
        "    result_text = result.text\n",
        "    \n",
        "    out_result = chatgpt_api(result_text)\n",
        "    \n",
        "    audioobj = gTTS(text = out_result, \n",
        "                    lang = language, \n",
        "                    slow = False)\n",
        "    \n",
        "    audioobj.save(\"Temp.mp3\")\n",
        "\n",
        "    return [result_text, out_result, \"Temp.mp3\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "aECnR3h5w0Rc",
        "outputId": "4529e10e-b0c4-4d88-8ebb-a4f7956d61cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "application/javascript": "(async (port, path, width, height, cache, element) => {\n                        if (!google.colab.kernel.accessAllowed && !cache) {\n                            return;\n                        }\n                        element.appendChild(document.createTextNode(''));\n                        const url = await google.colab.kernel.proxyPort(port, {cache});\n\n                        const external_link = document.createElement('div');\n                        external_link.innerHTML = `\n                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n                                    https://localhost:${port}${path}\n                                </a>\n                            </div>\n                        `;\n                        element.appendChild(external_link);\n\n                        const iframe = document.createElement('iframe');\n                        iframe.src = new URL(path, url).toString();\n                        iframe.height = height;\n                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n                        iframe.width = width;\n                        iframe.style.border = 0;\n                        element.appendChild(iframe);\n                    })(7863, \"/\", \"100%\", 500, false, window.element)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_1 = gr.Textbox(label=\"Speech to Text\")\n",
        "output_2 = gr.Textbox(label=\"ChatGPT Output\")\n",
        "output_3 = gr.Audio(\"Temp.mp3\")\n",
        "\n",
        "gr.Interface(\n",
        "    title = 'Voice Assistant for Visually Impaired People', \n",
        "    fn=transcribe, \n",
        "    inputs=[\n",
        "        gr.inputs.Audio(source=\"microphone\", type=\"filepath\")\n",
        "    ],\n",
        "\n",
        "    outputs=[\n",
        "        output_1,  output_2, output_3\n",
        "    ],\n",
        "    live=True).launch()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
